{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/varadhkaushik/Desktop/NEU/CS_5100-Foundations_of_AI/Projects/RL-models-for-Super-Mario-Bros/mario-env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'baselines'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m pyplot \u001b[39mas\u001b[39;00m plt\n\u001b[1;32m     11\u001b[0m \u001b[39m# from IPython.display import clear_output\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39m# get_ipython().run_line_magic('matplotlib', 'inline')\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwrappers\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnetworks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnetworks\u001b[39;00m \u001b[39mimport\u001b[39;00m DQN\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39magents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mDQN\u001b[39;00m \u001b[39mimport\u001b[39;00m Model \u001b[39mas\u001b[39;00m DQN_Agent\n",
      "File \u001b[0;32m~/Desktop/NEU/CS_5100-Foundations_of_AI/Projects/RL-models-for-Super-Mario-Bros/utils/wrappers.py:9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgym\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspaces\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbox\u001b[39;00m \u001b[39mimport\u001b[39;00m Box\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbaselines\u001b[39;00m \u001b[39mimport\u001b[39;00m bench\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbaselines\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39matari_wrappers\u001b[39;00m \u001b[39mimport\u001b[39;00m make_atari, wrap_deepmind\n\u001b[1;32m     12\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mImageToPyTorch\u001b[39;00m(gym\u001b[39m.\u001b[39mObservationWrapper):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'baselines'"
     ]
    }
   ],
   "source": [
    "import gym, math, glob\n",
    "import numpy as np\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "# from IPython.display import clear_output\n",
    "# get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "from utils.wrappers import *\n",
    "from networks.networks import DQN\n",
    "from agents.DQN import Model as DQN_Agent\n",
    "from networks.network_bodies import AtariBody\n",
    "from utils.ReplayMemory import ExperienceReplayMemory\n",
    "\n",
    "from utils.hyperparameters import Config\n",
    "from utils.plot import plot_all_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "\n",
    "config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#epsilon variables\n",
    "config.epsilon_start = 1.0\n",
    "config.epsilon_final = 0.01\n",
    "config.epsilon_decay = 30000\n",
    "config.epsilon_by_frame = lambda frame_idx: config.epsilon_final + (config.epsilon_start - config.epsilon_final) * math.exp(-1. * frame_idx / config.epsilon_decay)\n",
    "\n",
    "#misc agent variables\n",
    "config.GAMMA=0.99\n",
    "config.LR=1e-4\n",
    "\n",
    "#memory\n",
    "config.TARGET_NET_UPDATE_FREQ = 1000\n",
    "config.EXP_REPLAY_SIZE = 100000\n",
    "config.BATCH_SIZE = 32\n",
    "\n",
    "#Learning control variables\n",
    "config.LEARN_START = 10000\n",
    "config.MAX_FRAMES=1000000\n",
    "config.UPDATE_FREQ = 1\n",
    "\n",
    "#Nstep controls\n",
    "config.N_STEPS=1\n",
    "\n",
    "#data logging parameters\n",
    "config.ACTION_SELECTION_COUNT_FREQUENCY = 1000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(DQN_Agent):\n",
    "    def __init__(self, static_policy=False, env=None, config=None, log_dir='/tmp/gym'):\n",
    "        super(Model, self).__init__(static_policy, env, config, log_dir=log_dir)\n",
    "\n",
    "    def get_max_next_state_action(self, next_states):\n",
    "        return self.model(next_states).max(dim=1)[1].view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "start=timer()\n",
    "\n",
    "log_dir = \"/tmp/gym/\"\n",
    "try:\n",
    "    os.makedirs(log_dir)\n",
    "except OSError:\n",
    "    files = glob.glob(os.path.join(log_dir, '*.monitor.csv')) \\\n",
    "        + glob.glob(os.path.join(log_dir, '*td.csv')) \\\n",
    "        + glob.glob(os.path.join(log_dir, '*sig_param_mag.csv')) \\\n",
    "        + glob.glob(os.path.join(log_dir, '*action_log.csv'))\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "\n",
    "env_id = \"SuperMarioBros-v0\"\n",
    "env    = make_atari(env_id)\n",
    "env    = bench.Monitor(env, os.path.join(log_dir, env_id))\n",
    "env    = wrap_deepmind(env, episode_life=True, clip_rewards=True, frame_stack=False, scale=True)\n",
    "env    = WrapPyTorch(env)\n",
    "model  = Model(env=env, config=config, log_dir=log_dir)\n",
    "\n",
    "episode_reward = 0\n",
    "\n",
    "observation = env.reset()\n",
    "for frame_idx in range(1, config.MAX_FRAMES + 1):\n",
    "    epsilon = config.epsilon_by_frame(frame_idx)\n",
    "\n",
    "    action = model.get_action(observation, epsilon)\n",
    "    model.save_action(action, frame_idx) #log action selection\n",
    "\n",
    "    prev_observation=observation\n",
    "    observation, reward, done, _ = env.step(action)\n",
    "    observation = None if done else observation\n",
    "\n",
    "    model.update(prev_observation, action, reward, observation, frame_idx)\n",
    "    episode_reward += reward\n",
    "\n",
    "    if done:\n",
    "        model.finish_nstep()\n",
    "        model.reset_hx()\n",
    "        observation = env.reset()\n",
    "        model.save_reward(episode_reward)\n",
    "        episode_reward = 0\n",
    "\n",
    "    if frame_idx % 10000 == 0:\n",
    "        model.save_w()\n",
    "        try:\n",
    "            clear_output(True)\n",
    "            plot_all_data(log_dir, env_id, 'DoubleDQN', config.MAX_FRAMES, bin_size=(10, 100, 100, 1), smooth=1, time=timedelta(seconds=int(timer()-start)), ipynb=True)\n",
    "        except IOError:\n",
    "            pass\n",
    "\n",
    "model.save_w()\n",
    "env.close()\n",
    "plot_all_data(log_dir, env_id, 'DoubleDQN', config.MAX_FRAMES, bin_size=(10, 100, 100, 1), smooth=1, time=timedelta(seconds=int(timer()-start)), ipynb=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mario-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75b5ed7b3e537f206aa02f7ca89fc6abf621312b374a5b960d7edb3370f2ecfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
